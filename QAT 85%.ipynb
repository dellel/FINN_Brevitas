{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70f82bd-8fe9-4513-a6b3-ce591f69f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in /tmp/home_dir/.local/lib/python3.10/site-packages (1.0.14)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.14.1+cu116)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (1.13.1+cu116)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: safetensors in /tmp/home_dir/.local/lib/python3.10/site-packages (from timm) (0.5.2)\n",
      "Requirement already satisfied: huggingface_hub in /tmp/home_dir/.local/lib/python3.10/site-packages (from timm) (0.27.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.15.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /tmp/home_dir/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3df9e1-4e82-42ba-86a8-1dab6181e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import timm\n",
    "import brevitas.nn as qnn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from brevitas.core.quant import QuantType\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(2023)\n",
    "\n",
    "# Define your paths\n",
    "base_dir = os.environ['FINN_ROOT'] + \"/notebooks/FINN_Brevitas/\"\n",
    "data_path = base_dir + \"Dataset_BUSI_with_GT/\"\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transformations=None):\n",
    "        self.transformations = transformations\n",
    "        self.im_paths = []\n",
    "        self.cls_names = {}\n",
    "        \n",
    "        # Load all images and infer class labels from folder names\n",
    "        class_folders = sorted(glob(f\"{root}/*\"))  # e.g., Benign, Malignant, Normal\n",
    "        print(f\"Found class folders: {class_folders}\")\n",
    "        \n",
    "        for idx, folder in enumerate(class_folders):\n",
    "            class_name = os.path.basename(folder)  # e.g., \"Benign\"\n",
    "            self.cls_names[class_name] = idx\n",
    "            folder_images = glob(f\"{folder}/*.png\")\n",
    "            print(f\"Class '{class_name}' has {len(folder_images)} images.\")\n",
    "            self.im_paths.extend([(im_path, idx) for im_path in folder_images])\n",
    "        \n",
    "        self.im_paths.sort()  # Sort for reproducibility\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.im_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im_path, label = self.im_paths[idx]\n",
    "        im = Image.open(im_path).convert(\"L\")  # Convert to grayscale\n",
    "        if self.transformations:\n",
    "            im = self.transformations(im)\n",
    "        return im, label\n",
    "# Split dataset\n",
    "def split_dataset(dataset, train_ratio=0.8, val_ratio=0.1):\n",
    "    total_len = len(dataset)\n",
    "    train_len = int(total_len * train_ratio)\n",
    "    val_len = int(total_len * val_ratio)\n",
    "    test_len = total_len - train_len - val_len\n",
    "    return random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "# Dataloader Function\n",
    "def get_dls(root, transformations, bs, ns=4):\n",
    "    dataset = CustomDataset(root=root, transformations=transformations)\n",
    "    train_ds, val_ds, test_ds = split_dataset(dataset)\n",
    "    tr_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=4)\n",
    "    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    ts_dl = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=ns)\n",
    "    return tr_dl, val_dl, ts_dl, dataset.cls_names\n",
    "\n",
    "# Root path for dataset\n",
    "root = data_path\n",
    "# Define advanced transformations with grayscale and augmentations\n",
    "mean, std, im_size = [0.485], [0.229], 224\n",
    "tfs = T.Compose([\n",
    "    T.Resize((im_size, im_size)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(20),\n",
    "    T.RandomResizedCrop(im_size, scale=(0.8, 1.0)),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    T.RandomAffine(degrees=20, translate=(0.1, 0.1), shear=10),\n",
    "    T.RandomGrayscale(p=1.0),  # Ensure images are converted to grayscale\n",
    "    T.ToTensor(),\n",
    "    T.RandomErasing(p=0.2),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46866762-dc09-4793-9da4-06949a7d2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found class folders: ['/home/administrateur/finn/notebooks/FINN_Brevitas/Dataset_BUSI_with_GT/Benign', '/home/administrateur/finn/notebooks/FINN_Brevitas/Dataset_BUSI_with_GT/Malignant', '/home/administrateur/finn/notebooks/FINN_Brevitas/Dataset_BUSI_with_GT/Normal']\n",
      "Class 'Benign' has 437 images.\n",
      "Class 'Malignant' has 210 images.\n",
      "Class 'Normal' has 133 images.\n",
      "Number of batches in training loader: 39\n",
      "Number of batches in validation loader: 5\n",
      "Number of batches in test loader: 78\n",
      "Classes: {'Benign': 0, 'Malignant': 1, 'Normal': 2}\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "tr_dl, val_dl, ts_dl, classes = get_dls(root=root, transformations=tfs, bs=16)\n",
    "print(\"Number of batches in training loader:\", len(tr_dl))\n",
    "print(\"Number of batches in validation loader:\", len(val_dl))\n",
    "print(\"Number of batches in test loader:\", len(ts_dl))\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3c0414-3e0e-4be9-abe7-5a1d923966a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEBlock and ResidualBlock Definitions\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, _, _ = x.size()\n",
    "        y = self.global_pool(x).view(batch, channels)\n",
    "        y = self.fc2(self.act(self.fc1(y))).view(batch, channels, 1, 1)\n",
    "        y = self.sigmoid(y)\n",
    "        return x * y\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, use_se=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = qnn.QuantConv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, weight_bit_width=8, bias=False, quant_type=QuantType.INT)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.act1 = qnn.QuantReLU(bit_width=8, quant_type=QuantType.INT)\n",
    "        self.conv2 = qnn.QuantConv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, weight_bit_width=8, bias=False, quant_type=QuantType.INT)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.act2 = qnn.QuantReLU(bit_width=8, quant_type=QuantType.INT)\n",
    "        self.use_se = use_se\n",
    "        if use_se:\n",
    "            self.se = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.use_se:\n",
    "            out = self.se(out)\n",
    "        out += identity\n",
    "        out = self.act2(out)\n",
    "        return out\n",
    "\n",
    "# Model Definition\n",
    "class AdvancedUltrasoundNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AdvancedUltrasoundNet, self).__init__()\n",
    "        self.conv1 = qnn.QuantConv2d(1, 64, kernel_size=7, stride=2, padding=3, weight_bit_width=8, bias=False, quant_type=QuantType.INT)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.act1 = qnn.QuantReLU(bit_width=8, quant_type=QuantType.INT)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Residual Blocks with SE\n",
    "        self.res1 = ResidualBlock(64, 64, use_se=True)\n",
    "        self.res2 = ResidualBlock(64, 128, stride=2, downsample=self._downsample(64, 128), use_se=True)\n",
    "        self.res3 = ResidualBlock(128, 256, stride=2, downsample=self._downsample(128, 256), use_se=True)\n",
    "        self.res4 = ResidualBlock(256, 512, stride=2, downsample=self._downsample(256, 512), use_se=True)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = qnn.QuantLinear(512, 256, bias=True, weight_bit_width=8, quant_type=QuantType.INT)\n",
    "        self.act2 = qnn.QuantReLU(bit_width=8, quant_type=QuantType.INT)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = qnn.QuantLinear(256, 128, bias=True, weight_bit_width=8, quant_type=QuantType.INT)\n",
    "        self.fc3 = qnn.QuantLinear(128, num_classes, bias=True, weight_bit_width=8, quant_type=QuantType.INT)\n",
    "\n",
    "    def _downsample(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            qnn.QuantConv2d(in_channels, out_channels, kernel_size=1, stride=2, weight_bit_width=8, bias=False, quant_type=QuantType.INT),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.act1(self.bn1(self.conv1(x))))\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.res4(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(self.act2(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, criterion, optimizer, and scheduler\n",
    "model = AdvancedUltrasoundNet(num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff52df5-8f91-4812-a5ac-39fa9db12afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)  # Adjusted learning rate and weight decay\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=200, eta_min=1e-6)  # Adjusted Cosine Annealing with warm-up strategy\n",
    "clip_value = 1.0  # Gradient clipping to stabilize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc7857a-04d8-497f-8c76-8113c54f3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, tr_dl, val_dl, criterion, optimizer, scheduler, epochs=200):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tr_dl:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(tr_dl):.4f}, Accuracy: {100 * correct/total:.2f}%\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dl:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss/len(val_dl):.4f}, Validation Accuracy: {100 * correct_val/total_val:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e654f32-360a-4f44-a04b-86db43a9ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1255: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
      "  return super(Tensor, self).rename(names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 1.0190, Accuracy: 56.09%\n",
      "Validation Loss: 0.9579, Validation Accuracy: 53.85%\n",
      "Epoch [2/200], Loss: 0.9619, Accuracy: 55.93%\n",
      "Validation Loss: 0.8727, Validation Accuracy: 62.82%\n",
      "Epoch [3/200], Loss: 0.9408, Accuracy: 57.05%\n",
      "Validation Loss: 0.8581, Validation Accuracy: 62.82%\n",
      "Epoch [4/200], Loss: 0.9146, Accuracy: 58.17%\n",
      "Validation Loss: 0.7886, Validation Accuracy: 71.79%\n",
      "Epoch [5/200], Loss: 0.9020, Accuracy: 58.81%\n",
      "Validation Loss: 0.9192, Validation Accuracy: 55.13%\n",
      "Epoch [6/200], Loss: 0.8817, Accuracy: 59.78%\n",
      "Validation Loss: 0.8659, Validation Accuracy: 55.13%\n",
      "Epoch [7/200], Loss: 0.8548, Accuracy: 60.58%\n",
      "Validation Loss: 0.8426, Validation Accuracy: 56.41%\n",
      "Epoch [8/200], Loss: 0.8339, Accuracy: 62.98%\n",
      "Validation Loss: 0.6726, Validation Accuracy: 65.38%\n",
      "Epoch [9/200], Loss: 0.8023, Accuracy: 64.10%\n",
      "Validation Loss: 0.7437, Validation Accuracy: 65.38%\n",
      "Epoch [10/200], Loss: 0.7870, Accuracy: 65.06%\n",
      "Validation Loss: 0.6926, Validation Accuracy: 69.23%\n",
      "Epoch [11/200], Loss: 0.7797, Accuracy: 64.74%\n",
      "Validation Loss: 0.6511, Validation Accuracy: 74.36%\n",
      "Epoch [12/200], Loss: 0.7646, Accuracy: 66.35%\n",
      "Validation Loss: 0.6973, Validation Accuracy: 69.23%\n",
      "Epoch [13/200], Loss: 0.7615, Accuracy: 64.90%\n",
      "Validation Loss: 0.7792, Validation Accuracy: 65.38%\n",
      "Epoch [14/200], Loss: 0.7328, Accuracy: 68.43%\n",
      "Validation Loss: 0.8544, Validation Accuracy: 57.69%\n",
      "Epoch [15/200], Loss: 0.7330, Accuracy: 68.43%\n",
      "Validation Loss: 0.7285, Validation Accuracy: 70.51%\n",
      "Epoch [16/200], Loss: 0.7564, Accuracy: 67.31%\n",
      "Validation Loss: 0.8647, Validation Accuracy: 61.54%\n",
      "Epoch [17/200], Loss: 0.7361, Accuracy: 68.27%\n",
      "Validation Loss: 0.7971, Validation Accuracy: 64.10%\n",
      "Epoch [18/200], Loss: 0.7509, Accuracy: 66.67%\n",
      "Validation Loss: 0.7163, Validation Accuracy: 69.23%\n",
      "Epoch [19/200], Loss: 0.7078, Accuracy: 70.67%\n",
      "Validation Loss: 0.5579, Validation Accuracy: 80.77%\n",
      "Epoch [20/200], Loss: 0.6779, Accuracy: 71.79%\n",
      "Validation Loss: 0.7918, Validation Accuracy: 66.67%\n",
      "Epoch [21/200], Loss: 0.7132, Accuracy: 67.47%\n",
      "Validation Loss: 0.6756, Validation Accuracy: 71.79%\n",
      "Epoch [22/200], Loss: 0.6950, Accuracy: 71.63%\n",
      "Validation Loss: 0.6631, Validation Accuracy: 71.79%\n",
      "Epoch [23/200], Loss: 0.6812, Accuracy: 71.63%\n",
      "Validation Loss: 0.6476, Validation Accuracy: 69.23%\n",
      "Epoch [24/200], Loss: 0.7222, Accuracy: 68.91%\n",
      "Validation Loss: 0.6237, Validation Accuracy: 78.21%\n",
      "Epoch [25/200], Loss: 0.6576, Accuracy: 72.92%\n",
      "Validation Loss: 0.5809, Validation Accuracy: 78.21%\n",
      "Epoch [26/200], Loss: 0.6573, Accuracy: 71.79%\n",
      "Validation Loss: 0.4796, Validation Accuracy: 78.21%\n",
      "Epoch [27/200], Loss: 0.6533, Accuracy: 73.56%\n",
      "Validation Loss: 1.3456, Validation Accuracy: 34.62%\n",
      "Epoch [28/200], Loss: 0.6888, Accuracy: 70.99%\n",
      "Validation Loss: 0.5589, Validation Accuracy: 79.49%\n",
      "Epoch [29/200], Loss: 0.6504, Accuracy: 72.92%\n",
      "Validation Loss: 0.6000, Validation Accuracy: 79.49%\n",
      "Epoch [30/200], Loss: 0.6595, Accuracy: 74.04%\n",
      "Validation Loss: 0.6288, Validation Accuracy: 73.08%\n",
      "Epoch [31/200], Loss: 0.6561, Accuracy: 72.44%\n",
      "Validation Loss: 0.5690, Validation Accuracy: 80.77%\n",
      "Epoch [32/200], Loss: 0.6401, Accuracy: 72.92%\n",
      "Validation Loss: 0.5392, Validation Accuracy: 80.77%\n",
      "Epoch [33/200], Loss: 0.6471, Accuracy: 71.63%\n",
      "Validation Loss: 0.5732, Validation Accuracy: 80.77%\n",
      "Epoch [34/200], Loss: 0.6209, Accuracy: 73.56%\n",
      "Validation Loss: 0.6117, Validation Accuracy: 75.64%\n",
      "Epoch [35/200], Loss: 0.6212, Accuracy: 73.40%\n",
      "Validation Loss: 0.6549, Validation Accuracy: 74.36%\n",
      "Epoch [36/200], Loss: 0.6386, Accuracy: 73.40%\n",
      "Validation Loss: 0.5025, Validation Accuracy: 84.62%\n",
      "Epoch [37/200], Loss: 0.6271, Accuracy: 73.08%\n",
      "Validation Loss: 0.5583, Validation Accuracy: 73.08%\n",
      "Epoch [38/200], Loss: 0.5945, Accuracy: 73.88%\n",
      "Validation Loss: 0.5247, Validation Accuracy: 75.64%\n",
      "Epoch [39/200], Loss: 0.5828, Accuracy: 75.80%\n",
      "Validation Loss: 0.5160, Validation Accuracy: 82.05%\n",
      "Epoch [40/200], Loss: 0.5806, Accuracy: 75.48%\n",
      "Validation Loss: 0.5760, Validation Accuracy: 73.08%\n",
      "Epoch [41/200], Loss: 0.6121, Accuracy: 73.40%\n",
      "Validation Loss: 0.4589, Validation Accuracy: 79.49%\n",
      "Epoch [42/200], Loss: 0.5979, Accuracy: 75.00%\n",
      "Validation Loss: 0.4927, Validation Accuracy: 82.05%\n",
      "Epoch [43/200], Loss: 0.5932, Accuracy: 75.96%\n",
      "Validation Loss: 0.6881, Validation Accuracy: 73.08%\n",
      "Epoch [44/200], Loss: 0.5495, Accuracy: 76.92%\n",
      "Validation Loss: 0.6229, Validation Accuracy: 66.67%\n",
      "Epoch [45/200], Loss: 0.5909, Accuracy: 75.00%\n",
      "Validation Loss: 0.5450, Validation Accuracy: 75.64%\n",
      "Epoch [46/200], Loss: 0.5862, Accuracy: 74.20%\n",
      "Validation Loss: 0.6258, Validation Accuracy: 79.49%\n",
      "Epoch [47/200], Loss: 0.5634, Accuracy: 75.96%\n",
      "Validation Loss: 0.6034, Validation Accuracy: 75.64%\n",
      "Epoch [48/200], Loss: 0.5843, Accuracy: 75.16%\n",
      "Validation Loss: 0.7673, Validation Accuracy: 66.67%\n",
      "Epoch [49/200], Loss: 0.5496, Accuracy: 77.56%\n",
      "Validation Loss: 0.5925, Validation Accuracy: 73.08%\n",
      "Epoch [50/200], Loss: 0.5648, Accuracy: 75.80%\n",
      "Validation Loss: 0.7014, Validation Accuracy: 66.67%\n",
      "Epoch [51/200], Loss: 0.5844, Accuracy: 76.28%\n",
      "Validation Loss: 0.5575, Validation Accuracy: 75.64%\n",
      "Epoch [52/200], Loss: 0.5395, Accuracy: 78.04%\n",
      "Validation Loss: 0.5223, Validation Accuracy: 78.21%\n",
      "Epoch [53/200], Loss: 0.5373, Accuracy: 78.53%\n",
      "Validation Loss: 0.6143, Validation Accuracy: 73.08%\n",
      "Epoch [54/200], Loss: 0.5361, Accuracy: 78.04%\n",
      "Validation Loss: 0.7717, Validation Accuracy: 65.38%\n",
      "Epoch [55/200], Loss: 0.5146, Accuracy: 79.65%\n",
      "Validation Loss: 0.8562, Validation Accuracy: 64.10%\n",
      "Epoch [56/200], Loss: 0.5012, Accuracy: 79.01%\n",
      "Validation Loss: 0.5219, Validation Accuracy: 79.49%\n",
      "Epoch [57/200], Loss: 0.5157, Accuracy: 78.04%\n",
      "Validation Loss: 0.6320, Validation Accuracy: 69.23%\n",
      "Epoch [58/200], Loss: 0.5192, Accuracy: 78.53%\n",
      "Validation Loss: 0.5258, Validation Accuracy: 79.49%\n",
      "Epoch [59/200], Loss: 0.5104, Accuracy: 79.17%\n",
      "Validation Loss: 0.3981, Validation Accuracy: 82.05%\n",
      "Epoch [60/200], Loss: 0.5217, Accuracy: 79.97%\n",
      "Validation Loss: 0.4913, Validation Accuracy: 74.36%\n",
      "Epoch [61/200], Loss: 0.4867, Accuracy: 79.81%\n",
      "Validation Loss: 0.3593, Validation Accuracy: 84.62%\n",
      "Epoch [62/200], Loss: 0.4791, Accuracy: 81.41%\n",
      "Validation Loss: 0.6754, Validation Accuracy: 67.95%\n",
      "Epoch [63/200], Loss: 0.4601, Accuracy: 81.57%\n",
      "Validation Loss: 1.0546, Validation Accuracy: 61.54%\n",
      "Epoch [64/200], Loss: 0.4817, Accuracy: 80.13%\n",
      "Validation Loss: 0.5108, Validation Accuracy: 79.49%\n",
      "Epoch [65/200], Loss: 0.5004, Accuracy: 79.49%\n",
      "Validation Loss: 0.5423, Validation Accuracy: 74.36%\n",
      "Epoch [66/200], Loss: 0.5003, Accuracy: 78.85%\n",
      "Validation Loss: 0.4192, Validation Accuracy: 82.05%\n",
      "Epoch [67/200], Loss: 0.4933, Accuracy: 79.17%\n",
      "Validation Loss: 0.5674, Validation Accuracy: 75.64%\n",
      "Epoch [68/200], Loss: 0.4629, Accuracy: 82.37%\n",
      "Validation Loss: 0.6093, Validation Accuracy: 79.49%\n",
      "Epoch [69/200], Loss: 0.4486, Accuracy: 81.73%\n",
      "Validation Loss: 0.7165, Validation Accuracy: 73.08%\n",
      "Epoch [70/200], Loss: 0.4540, Accuracy: 80.77%\n",
      "Validation Loss: 0.4297, Validation Accuracy: 80.77%\n",
      "Epoch [71/200], Loss: 0.4170, Accuracy: 82.85%\n",
      "Validation Loss: 0.5002, Validation Accuracy: 78.21%\n",
      "Epoch [72/200], Loss: 0.4180, Accuracy: 83.97%\n",
      "Validation Loss: 0.4901, Validation Accuracy: 79.49%\n",
      "Epoch [73/200], Loss: 0.4417, Accuracy: 83.17%\n",
      "Validation Loss: 0.4256, Validation Accuracy: 80.77%\n",
      "Epoch [74/200], Loss: 0.4521, Accuracy: 80.29%\n",
      "Validation Loss: 0.6937, Validation Accuracy: 70.51%\n",
      "Epoch [75/200], Loss: 0.4068, Accuracy: 83.65%\n",
      "Validation Loss: 0.5616, Validation Accuracy: 74.36%\n",
      "Epoch [76/200], Loss: 0.4481, Accuracy: 82.05%\n",
      "Validation Loss: 0.5710, Validation Accuracy: 75.64%\n",
      "Epoch [77/200], Loss: 0.4052, Accuracy: 82.37%\n",
      "Validation Loss: 0.6999, Validation Accuracy: 74.36%\n",
      "Epoch [78/200], Loss: 0.4250, Accuracy: 83.81%\n",
      "Validation Loss: 0.4314, Validation Accuracy: 80.77%\n",
      "Epoch [79/200], Loss: 0.4032, Accuracy: 83.65%\n",
      "Validation Loss: 0.5189, Validation Accuracy: 82.05%\n",
      "Epoch [80/200], Loss: 0.4468, Accuracy: 81.25%\n",
      "Validation Loss: 0.6660, Validation Accuracy: 74.36%\n",
      "Epoch [81/200], Loss: 0.4144, Accuracy: 82.85%\n",
      "Validation Loss: 0.6069, Validation Accuracy: 80.77%\n",
      "Epoch [82/200], Loss: 0.4163, Accuracy: 83.01%\n",
      "Validation Loss: 0.3769, Validation Accuracy: 80.77%\n",
      "Epoch [83/200], Loss: 0.3718, Accuracy: 85.26%\n",
      "Validation Loss: 0.4437, Validation Accuracy: 82.05%\n",
      "Epoch [84/200], Loss: 0.3927, Accuracy: 84.78%\n",
      "Validation Loss: 0.5543, Validation Accuracy: 76.92%\n",
      "Epoch [85/200], Loss: 0.3933, Accuracy: 84.29%\n",
      "Validation Loss: 0.6104, Validation Accuracy: 74.36%\n",
      "Epoch [86/200], Loss: 0.3925, Accuracy: 84.62%\n",
      "Validation Loss: 0.5434, Validation Accuracy: 79.49%\n",
      "Epoch [87/200], Loss: 0.4017, Accuracy: 83.17%\n",
      "Validation Loss: 0.5254, Validation Accuracy: 80.77%\n",
      "Epoch [88/200], Loss: 0.4335, Accuracy: 83.65%\n",
      "Validation Loss: 0.6929, Validation Accuracy: 69.23%\n",
      "Epoch [89/200], Loss: 0.4125, Accuracy: 83.17%\n",
      "Validation Loss: 0.5407, Validation Accuracy: 74.36%\n",
      "Epoch [90/200], Loss: 0.3667, Accuracy: 85.10%\n",
      "Validation Loss: 0.4687, Validation Accuracy: 76.92%\n",
      "Epoch [91/200], Loss: 0.3417, Accuracy: 86.06%\n",
      "Validation Loss: 0.7282, Validation Accuracy: 64.10%\n",
      "Epoch [92/200], Loss: 0.4040, Accuracy: 83.33%\n",
      "Validation Loss: 0.5285, Validation Accuracy: 76.92%\n",
      "Epoch [93/200], Loss: 0.3694, Accuracy: 87.02%\n",
      "Validation Loss: 0.4476, Validation Accuracy: 80.77%\n",
      "Epoch [94/200], Loss: 0.3448, Accuracy: 86.54%\n",
      "Validation Loss: 0.6561, Validation Accuracy: 73.08%\n",
      "Epoch [95/200], Loss: 0.3857, Accuracy: 85.26%\n",
      "Validation Loss: 0.5070, Validation Accuracy: 79.49%\n",
      "Epoch [96/200], Loss: 0.3708, Accuracy: 84.94%\n",
      "Validation Loss: 0.4697, Validation Accuracy: 78.21%\n",
      "Epoch [97/200], Loss: 0.3327, Accuracy: 87.82%\n",
      "Validation Loss: 0.6241, Validation Accuracy: 80.77%\n",
      "Epoch [98/200], Loss: 0.3703, Accuracy: 86.06%\n",
      "Validation Loss: 0.6614, Validation Accuracy: 75.64%\n",
      "Epoch [99/200], Loss: 0.3921, Accuracy: 84.29%\n",
      "Validation Loss: 0.4779, Validation Accuracy: 82.05%\n",
      "Epoch [100/200], Loss: 0.3333, Accuracy: 86.54%\n",
      "Validation Loss: 0.6148, Validation Accuracy: 78.21%\n",
      "Epoch [101/200], Loss: 0.3734, Accuracy: 86.54%\n",
      "Validation Loss: 0.5689, Validation Accuracy: 76.92%\n",
      "Epoch [102/200], Loss: 0.3356, Accuracy: 86.38%\n",
      "Validation Loss: 0.3983, Validation Accuracy: 85.90%\n",
      "Epoch [103/200], Loss: 0.3190, Accuracy: 88.14%\n",
      "Validation Loss: 0.5221, Validation Accuracy: 78.21%\n",
      "Epoch [104/200], Loss: 0.3251, Accuracy: 87.02%\n",
      "Validation Loss: 0.4885, Validation Accuracy: 74.36%\n",
      "Epoch [105/200], Loss: 0.3351, Accuracy: 86.70%\n",
      "Validation Loss: 0.5495, Validation Accuracy: 82.05%\n",
      "Epoch [106/200], Loss: 0.3155, Accuracy: 87.02%\n",
      "Validation Loss: 0.6295, Validation Accuracy: 76.92%\n",
      "Epoch [107/200], Loss: 0.3166, Accuracy: 86.38%\n",
      "Validation Loss: 0.4497, Validation Accuracy: 83.33%\n",
      "Epoch [108/200], Loss: 0.3226, Accuracy: 87.82%\n",
      "Validation Loss: 0.8132, Validation Accuracy: 66.67%\n",
      "Epoch [109/200], Loss: 0.3467, Accuracy: 87.02%\n",
      "Validation Loss: 0.4957, Validation Accuracy: 80.77%\n",
      "Epoch [110/200], Loss: 0.3184, Accuracy: 88.78%\n",
      "Validation Loss: 0.5303, Validation Accuracy: 78.21%\n",
      "Epoch [111/200], Loss: 0.3489, Accuracy: 86.86%\n",
      "Validation Loss: 0.5591, Validation Accuracy: 78.21%\n",
      "Epoch [112/200], Loss: 0.3200, Accuracy: 88.30%\n",
      "Validation Loss: 0.5076, Validation Accuracy: 78.21%\n",
      "Epoch [113/200], Loss: 0.3030, Accuracy: 88.62%\n",
      "Validation Loss: 0.5431, Validation Accuracy: 79.49%\n",
      "Epoch [114/200], Loss: 0.3048, Accuracy: 87.98%\n",
      "Validation Loss: 0.5589, Validation Accuracy: 79.49%\n",
      "Epoch [115/200], Loss: 0.2908, Accuracy: 88.14%\n",
      "Validation Loss: 0.4619, Validation Accuracy: 84.62%\n",
      "Epoch [116/200], Loss: 0.2673, Accuracy: 89.10%\n",
      "Validation Loss: 0.5084, Validation Accuracy: 83.33%\n",
      "Epoch [117/200], Loss: 0.2934, Accuracy: 88.78%\n",
      "Validation Loss: 0.5176, Validation Accuracy: 78.21%\n",
      "Epoch [118/200], Loss: 0.2579, Accuracy: 90.87%\n",
      "Validation Loss: 0.5642, Validation Accuracy: 79.49%\n",
      "Epoch [119/200], Loss: 0.2849, Accuracy: 87.82%\n",
      "Validation Loss: 0.4596, Validation Accuracy: 79.49%\n",
      "Epoch [120/200], Loss: 0.3011, Accuracy: 88.78%\n",
      "Validation Loss: 0.5036, Validation Accuracy: 78.21%\n",
      "Epoch [121/200], Loss: 0.2529, Accuracy: 89.74%\n",
      "Validation Loss: 0.6835, Validation Accuracy: 71.79%\n",
      "Epoch [122/200], Loss: 0.3146, Accuracy: 87.50%\n",
      "Validation Loss: 0.4794, Validation Accuracy: 80.77%\n",
      "Epoch [123/200], Loss: 0.2495, Accuracy: 89.42%\n",
      "Validation Loss: 0.4989, Validation Accuracy: 82.05%\n",
      "Epoch [124/200], Loss: 0.2923, Accuracy: 87.82%\n",
      "Validation Loss: 0.6035, Validation Accuracy: 78.21%\n",
      "Epoch [125/200], Loss: 0.2469, Accuracy: 90.06%\n",
      "Validation Loss: 0.5368, Validation Accuracy: 83.33%\n",
      "Epoch [126/200], Loss: 0.3124, Accuracy: 89.10%\n",
      "Validation Loss: 0.5296, Validation Accuracy: 80.77%\n",
      "Epoch [127/200], Loss: 0.3010, Accuracy: 89.58%\n",
      "Validation Loss: 0.4594, Validation Accuracy: 83.33%\n",
      "Epoch [128/200], Loss: 0.2629, Accuracy: 90.38%\n",
      "Validation Loss: 0.7158, Validation Accuracy: 74.36%\n",
      "Epoch [129/200], Loss: 0.3049, Accuracy: 89.58%\n",
      "Validation Loss: 0.4424, Validation Accuracy: 82.05%\n",
      "Epoch [130/200], Loss: 0.2460, Accuracy: 90.71%\n",
      "Validation Loss: 0.6280, Validation Accuracy: 73.08%\n",
      "Epoch [131/200], Loss: 0.2237, Accuracy: 90.87%\n",
      "Validation Loss: 0.3820, Validation Accuracy: 83.33%\n",
      "Epoch [132/200], Loss: 0.2354, Accuracy: 90.54%\n",
      "Validation Loss: 0.4937, Validation Accuracy: 82.05%\n",
      "Epoch [133/200], Loss: 0.2748, Accuracy: 90.38%\n",
      "Validation Loss: 0.5105, Validation Accuracy: 84.62%\n",
      "Epoch [134/200], Loss: 0.2237, Accuracy: 91.51%\n",
      "Validation Loss: 0.7237, Validation Accuracy: 75.64%\n",
      "Epoch [135/200], Loss: 0.2815, Accuracy: 89.26%\n",
      "Validation Loss: 0.5350, Validation Accuracy: 79.49%\n",
      "Epoch [136/200], Loss: 0.2979, Accuracy: 89.26%\n",
      "Validation Loss: 0.4055, Validation Accuracy: 83.33%\n",
      "Epoch [137/200], Loss: 0.2309, Accuracy: 89.74%\n",
      "Validation Loss: 0.5031, Validation Accuracy: 83.33%\n",
      "Epoch [138/200], Loss: 0.2145, Accuracy: 92.63%\n",
      "Validation Loss: 0.5949, Validation Accuracy: 78.21%\n",
      "Epoch [139/200], Loss: 0.2526, Accuracy: 90.54%\n",
      "Validation Loss: 0.3876, Validation Accuracy: 87.18%\n",
      "Epoch [140/200], Loss: 0.2188, Accuracy: 91.83%\n",
      "Validation Loss: 0.5201, Validation Accuracy: 82.05%\n",
      "Epoch [141/200], Loss: 0.1964, Accuracy: 91.67%\n",
      "Validation Loss: 0.5424, Validation Accuracy: 79.49%\n",
      "Epoch [142/200], Loss: 0.2722, Accuracy: 91.19%\n",
      "Validation Loss: 0.4784, Validation Accuracy: 76.92%\n",
      "Epoch [143/200], Loss: 0.2333, Accuracy: 90.87%\n",
      "Validation Loss: 0.4806, Validation Accuracy: 76.92%\n",
      "Epoch [144/200], Loss: 0.2384, Accuracy: 91.03%\n",
      "Validation Loss: 0.4013, Validation Accuracy: 82.05%\n",
      "Epoch [145/200], Loss: 0.2658, Accuracy: 89.26%\n",
      "Validation Loss: 0.5776, Validation Accuracy: 78.21%\n",
      "Epoch [146/200], Loss: 0.1930, Accuracy: 92.15%\n",
      "Validation Loss: 0.2862, Validation Accuracy: 89.74%\n",
      "Epoch [147/200], Loss: 0.2278, Accuracy: 91.67%\n",
      "Validation Loss: 0.6008, Validation Accuracy: 79.49%\n",
      "Epoch [148/200], Loss: 0.2287, Accuracy: 91.35%\n",
      "Validation Loss: 0.5720, Validation Accuracy: 80.77%\n",
      "Epoch [149/200], Loss: 0.1961, Accuracy: 91.51%\n",
      "Validation Loss: 0.5738, Validation Accuracy: 84.62%\n",
      "Epoch [150/200], Loss: 0.2361, Accuracy: 91.03%\n",
      "Validation Loss: 0.3755, Validation Accuracy: 84.62%\n",
      "Epoch [151/200], Loss: 0.2727, Accuracy: 89.58%\n",
      "Validation Loss: 0.4255, Validation Accuracy: 84.62%\n",
      "Epoch [152/200], Loss: 0.2027, Accuracy: 91.83%\n",
      "Validation Loss: 0.7338, Validation Accuracy: 75.64%\n",
      "Epoch [153/200], Loss: 0.2477, Accuracy: 91.67%\n",
      "Validation Loss: 0.4937, Validation Accuracy: 78.21%\n",
      "Epoch [154/200], Loss: 0.2052, Accuracy: 92.15%\n",
      "Validation Loss: 0.4584, Validation Accuracy: 82.05%\n",
      "Epoch [155/200], Loss: 0.1732, Accuracy: 92.15%\n",
      "Validation Loss: 0.4966, Validation Accuracy: 82.05%\n",
      "Epoch [156/200], Loss: 0.2056, Accuracy: 92.15%\n",
      "Validation Loss: 0.6394, Validation Accuracy: 76.92%\n",
      "Epoch [157/200], Loss: 0.2243, Accuracy: 91.67%\n",
      "Validation Loss: 0.5473, Validation Accuracy: 78.21%\n",
      "Epoch [158/200], Loss: 0.2257, Accuracy: 91.67%\n",
      "Validation Loss: 0.3663, Validation Accuracy: 84.62%\n",
      "Epoch [159/200], Loss: 0.2031, Accuracy: 92.31%\n",
      "Validation Loss: 0.5610, Validation Accuracy: 79.49%\n",
      "Epoch [160/200], Loss: 0.2272, Accuracy: 91.83%\n",
      "Validation Loss: 0.5499, Validation Accuracy: 83.33%\n",
      "Epoch [161/200], Loss: 0.1839, Accuracy: 91.67%\n",
      "Validation Loss: 0.5434, Validation Accuracy: 75.64%\n",
      "Epoch [162/200], Loss: 0.1916, Accuracy: 91.67%\n",
      "Validation Loss: 0.4809, Validation Accuracy: 83.33%\n",
      "Epoch [163/200], Loss: 0.1855, Accuracy: 92.63%\n",
      "Validation Loss: 0.5102, Validation Accuracy: 82.05%\n",
      "Epoch [164/200], Loss: 0.1904, Accuracy: 92.31%\n",
      "Validation Loss: 0.5407, Validation Accuracy: 84.62%\n",
      "Epoch [165/200], Loss: 0.1772, Accuracy: 92.95%\n",
      "Validation Loss: 0.4613, Validation Accuracy: 84.62%\n",
      "Epoch [166/200], Loss: 0.2647, Accuracy: 90.22%\n",
      "Validation Loss: 0.5393, Validation Accuracy: 83.33%\n",
      "Epoch [167/200], Loss: 0.1879, Accuracy: 93.75%\n",
      "Validation Loss: 0.5983, Validation Accuracy: 82.05%\n",
      "Epoch [168/200], Loss: 0.1942, Accuracy: 91.99%\n",
      "Validation Loss: 0.4569, Validation Accuracy: 85.90%\n",
      "Epoch [169/200], Loss: 0.2194, Accuracy: 91.35%\n",
      "Validation Loss: 0.5076, Validation Accuracy: 79.49%\n",
      "Epoch [170/200], Loss: 0.2100, Accuracy: 91.99%\n",
      "Validation Loss: 0.4430, Validation Accuracy: 80.77%\n",
      "Epoch [171/200], Loss: 0.1928, Accuracy: 93.43%\n",
      "Validation Loss: 0.7294, Validation Accuracy: 79.49%\n",
      "Epoch [172/200], Loss: 0.2136, Accuracy: 92.47%\n",
      "Validation Loss: 0.6159, Validation Accuracy: 82.05%\n",
      "Epoch [173/200], Loss: 0.1971, Accuracy: 93.27%\n",
      "Validation Loss: 0.4754, Validation Accuracy: 85.90%\n",
      "Epoch [174/200], Loss: 0.2321, Accuracy: 90.54%\n",
      "Validation Loss: 0.5034, Validation Accuracy: 82.05%\n",
      "Epoch [175/200], Loss: 0.1968, Accuracy: 93.11%\n",
      "Validation Loss: 0.5525, Validation Accuracy: 76.92%\n",
      "Epoch [176/200], Loss: 0.2007, Accuracy: 93.27%\n",
      "Validation Loss: 0.3051, Validation Accuracy: 85.90%\n",
      "Epoch [177/200], Loss: 0.2018, Accuracy: 92.63%\n",
      "Validation Loss: 0.4879, Validation Accuracy: 83.33%\n",
      "Epoch [178/200], Loss: 0.1928, Accuracy: 93.43%\n",
      "Validation Loss: 0.4762, Validation Accuracy: 82.05%\n",
      "Epoch [179/200], Loss: 0.1661, Accuracy: 94.07%\n",
      "Validation Loss: 0.4448, Validation Accuracy: 88.46%\n",
      "Epoch [180/200], Loss: 0.1638, Accuracy: 93.91%\n",
      "Validation Loss: 0.4433, Validation Accuracy: 84.62%\n",
      "Epoch [181/200], Loss: 0.1943, Accuracy: 93.11%\n",
      "Validation Loss: 0.5578, Validation Accuracy: 82.05%\n",
      "Epoch [182/200], Loss: 0.1799, Accuracy: 93.59%\n",
      "Validation Loss: 0.4812, Validation Accuracy: 85.90%\n",
      "Epoch [183/200], Loss: 0.1871, Accuracy: 92.95%\n",
      "Validation Loss: 0.5261, Validation Accuracy: 82.05%\n",
      "Epoch [184/200], Loss: 0.2270, Accuracy: 91.83%\n",
      "Validation Loss: 0.3960, Validation Accuracy: 85.90%\n",
      "Epoch [185/200], Loss: 0.1812, Accuracy: 94.23%\n",
      "Validation Loss: 0.3272, Validation Accuracy: 89.74%\n",
      "Epoch [186/200], Loss: 0.2220, Accuracy: 91.35%\n",
      "Validation Loss: 0.5538, Validation Accuracy: 82.05%\n",
      "Epoch [187/200], Loss: 0.1563, Accuracy: 94.87%\n",
      "Validation Loss: 0.5440, Validation Accuracy: 80.77%\n",
      "Epoch [188/200], Loss: 0.1918, Accuracy: 91.99%\n",
      "Validation Loss: 0.5276, Validation Accuracy: 83.33%\n",
      "Epoch [189/200], Loss: 0.1401, Accuracy: 95.19%\n",
      "Validation Loss: 0.4439, Validation Accuracy: 84.62%\n",
      "Epoch [190/200], Loss: 0.1701, Accuracy: 93.75%\n",
      "Validation Loss: 0.4970, Validation Accuracy: 82.05%\n",
      "Epoch [191/200], Loss: 0.1566, Accuracy: 93.75%\n",
      "Validation Loss: 0.5199, Validation Accuracy: 85.90%\n",
      "Epoch [192/200], Loss: 0.2112, Accuracy: 91.99%\n",
      "Validation Loss: 0.4042, Validation Accuracy: 87.18%\n",
      "Epoch [193/200], Loss: 0.1907, Accuracy: 93.27%\n",
      "Validation Loss: 0.5613, Validation Accuracy: 80.77%\n",
      "Epoch [194/200], Loss: 0.2104, Accuracy: 91.99%\n",
      "Validation Loss: 0.5528, Validation Accuracy: 76.92%\n",
      "Epoch [195/200], Loss: 0.1504, Accuracy: 94.39%\n",
      "Validation Loss: 0.5501, Validation Accuracy: 80.77%\n",
      "Epoch [196/200], Loss: 0.1969, Accuracy: 92.95%\n",
      "Validation Loss: 0.3473, Validation Accuracy: 89.74%\n",
      "Epoch [197/200], Loss: 0.1664, Accuracy: 93.43%\n",
      "Validation Loss: 0.4396, Validation Accuracy: 80.77%\n",
      "Epoch [198/200], Loss: 0.1297, Accuracy: 95.67%\n",
      "Validation Loss: 0.4253, Validation Accuracy: 83.33%\n",
      "Epoch [199/200], Loss: 0.2206, Accuracy: 92.79%\n",
      "Validation Loss: 0.4416, Validation Accuracy: 85.90%\n",
      "Epoch [200/200], Loss: 0.1731, Accuracy: 93.59%\n",
      "Validation Loss: 0.5477, Validation Accuracy: 79.49%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, tr_dl, val_dl, criterion, optimizer, scheduler, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d630e55-1516-40a8-94cf-a1f6c6664fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"resquantized_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bd0f6-0451-4ef9-b891-aed8d90fcea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in ts_dl:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct_test/total_test:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
